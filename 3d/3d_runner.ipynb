{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%matplotlib inline\n",
    "import os, sys, re\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn\n",
    "\n",
    "from random import randrange\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install opencv-python -qqq\n",
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "wandb.login()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvalenetjong\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import argparse\n",
    "\"\"\" Training and hyperparameter search configurations \"\"\"\n",
    "curr_dir = os.getcwd()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Final')\n",
    "parser.add_argument('--img_dir', type=str, default='/Users/valenetjong/Downloads/Data-3',\n",
    "                    help='directory for image storage')\n",
    "parser.add_argument('--seed', type=int, default=1,\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--num_classes', type=int, default=3,\n",
    "                    help='number of classes')\n",
    "parser.add_argument('--process_flag', type=bool, default=False,\n",
    "                    help=\"extract files from disk if True, use already extracted files, if False\")\n",
    "parser.add_argument('--create_dataset', type=bool, default=False,\n",
    "                    help=\"create dataset from scratch if True, load in processed dataset if False\")\n",
    "parser.add_argument('--transforms', type=str, default='all',\n",
    "                    help='transforms for data augmentation')\n",
    "parser.add_argument('--threshold', type=float, default=3e-4,\n",
    "                    help='early stopping criterion')\n",
    "args = parser.parse_args('')\n",
    "# Set random seed to reproduce results\n",
    "torch.manual_seed(args.seed)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1294052b0>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\"\"\" Set-up wandb \"\"\"\n",
    "sweep_config = {\n",
    "    'method': 'bayes'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'max val acc',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "params = {\n",
    "    'max_epochs': {\n",
    "        'value': 250\n",
    "        },\n",
    "    'hidden_size': {\n",
    "        'values': [8, 16],\n",
    "        },\n",
    "    'fc_size': {\n",
    "        'values': [32, 64, 128, 256, 512]\n",
    "        },\n",
    "    'conv_in_size': {\n",
    "        'values': [32, 64, 128, 256]\n",
    "        },\n",
    "    'conv_hid_size': {\n",
    "        'values': [8, 16, 32]\n",
    "        },\n",
    "    'conv_out_size': {\n",
    "        'values': [8, 16, 32]\n",
    "        },\n",
    "    'dropout': {\n",
    "          'values': [0.15, 0.2, 0.25, 0.3]\n",
    "        },\n",
    "    'batch_size': {\n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 8,\n",
    "        'min': 8,\n",
    "        'max': 64,\n",
    "        },\n",
    "    'lr': {\n",
    "        'values': [1e-3, 1e-4, 1e-5]\n",
    "        },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = params\n",
    "# sweep_id = wandb.sweep(sweep_config, project=\"3D-masked-imgs\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download Files\n",
    "Available at: https://www.kaggle.com/datasets/ninadaithal/imagesoasis/download?datasetVersionNumber=1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# 248,358\n",
    "# Preprocessing configurations\n",
    "CONV_WIDTH = 137\n",
    "CONV_HEIGHT = 167\n",
    "DEMENTIA_TYPES = ['Mild Dementia', 'Moderate Dementia', 'Non Demented']\n",
    "VIEWS = ['mpr-1']  # Corresponding to tra\n",
    "\n",
    "\n",
    "def normalize_intensity(img):\n",
    "    \"\"\"\n",
    "    Normalizes the intensity of an image to the range [0, 255].\n",
    "    \"\"\"\n",
    "    img_min = img.min()\n",
    "    img_max = img.max()\n",
    "    normalized_img = (img - img_min) / (img_max - img_min) * 255\n",
    "    return normalized_img.astype(np.uint8)\n",
    "\n",
    "def pad_image_to_size(img, width, height):\n",
    "    \"\"\"\n",
    "    Resizes and pads an image with zeros to the specified width and height.\n",
    "    \"\"\"\n",
    "    # Resize the image to fit within the specified dimensions while maintaining aspect ratio\n",
    "    scale = min(width / img.shape[1], height / img.shape[0])\n",
    "    resized_img = cv.resize(img, None, fx=scale, fy=scale, interpolation=cv.INTER_AREA)\n",
    "\n",
    "    # Calculate padding sizes\n",
    "    y_pad = max(height - resized_img.shape[0], 0)\n",
    "    x_pad = max(width - resized_img.shape[1], 0)\n",
    "    y_offset = y_pad // 2\n",
    "    x_offset = x_pad // 2\n",
    "\n",
    "    # Create a padded image with the specified dimensions\n",
    "    padded_img = np.zeros((height, width), dtype=resized_img.dtype)\n",
    "    padded_img[y_offset:y_offset+resized_img.shape[0], x_offset:x_offset+resized_img.shape[1]] = resized_img\n",
    "    return padded_img\n",
    "\n",
    "def crop_black_boundary(mri_image):\n",
    "    \"\"\"\n",
    "    Crops the black boundary from an MRI image.\n",
    "    \"\"\"\n",
    "    _, thresh = cv.threshold(mri_image, 1, 255, cv.THRESH_BINARY)\n",
    "    contours, _ = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = max(contours, key=cv.contourArea)\n",
    "    x, y, w, h = cv.boundingRect(largest_contour)\n",
    "    cropped_image = mri_image[y:y+h, x:x+w]\n",
    "    return cropped_image\n",
    "\n",
    "def process_image_stack(filenames):\n",
    "    \"\"\"\n",
    "    Processes a stack of MRI images and returns them as a single 3D array.\n",
    "    \"\"\"\n",
    "    image_stack = []\n",
    "    for fn in filenames:\n",
    "        with Image.open(fn) as img:\n",
    "            img = np.array(img.convert('L'))  # Convert to grayscale\n",
    "        img = crop_black_boundary(img)\n",
    "        img = normalize_intensity(img)\n",
    "        img = pad_image_to_size(img, CONV_WIDTH, CONV_HEIGHT)\n",
    "        image_stack.append(img)\n",
    "\n",
    "        print(f\"Processed {fn}, shape after padding: {img.shape}\")\n",
    "\n",
    "    stacked_img = np.stack(image_stack, axis=-1)\n",
    "    print(f\"Stacked image shape: {stacked_img.shape}\")\n",
    "    return stacked_img\n",
    "\n",
    "def preprocess_data(data_folder, output_folder):\n",
    "    print(\"Starting preprocessing...\")\n",
    "\n",
    "    for dementia_type in DEMENTIA_TYPES:\n",
    "        dementia_folder = os.path.join(data_folder, dementia_type)\n",
    "        if not os.path.exists(dementia_folder):\n",
    "            print(f\"Warning: Folder not found - {dementia_folder}\")\n",
    "            continue\n",
    "\n",
    "        # Collect unique patient IDs based on the file naming convention\n",
    "        patient_ids = set()\n",
    "        for filename in os.listdir(dementia_folder):\n",
    "            if 'mpr-1' in filename and filename.endswith('.jpg'):\n",
    "                patient_id = filename.split('_mpr')[0]  # Extract patient ID\n",
    "                patient_ids.add(patient_id)\n",
    "\n",
    "        # Process each patient's images\n",
    "        for patient_id in patient_ids:\n",
    "            view_images = sorted([f for f in os.listdir(dementia_folder) if patient_id in f and 'mpr-1' in f])\n",
    "\n",
    "            # Ensure we have images for mpr-1 view before proceeding\n",
    "            if view_images:\n",
    "                file_paths = [os.path.join(dementia_folder, img) for img in view_images]\n",
    "                stacked_img = process_image_stack(file_paths)\n",
    "\n",
    "                # Create directory for saving processed images if it doesn't exist\n",
    "                output_subdir = os.path.join(output_folder, dementia_type)\n",
    "                os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "                # Save the stacked image as a NumPy array\n",
    "                output_path = os.path.join(output_subdir, f'{patient_id}_3D.npy')\n",
    "                np.save(output_path, stacked_img)\n",
    "                print(f'Saved 3D image for patient {patient_id} in {output_subdir}')\n",
    "            else:\n",
    "                print(f\"Warning: No images found for mpr-1 for patient {patient_id} in {dementia_type}\")\n",
    "\n",
    "data_folder = './Data_now'\n",
    "output_folder = './3D_data'\n",
    "preprocess_data(data_folder, output_folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "base_directory = args.img_dir  # Replace with your path\n",
    "class_counts = load_images_to_tensor(base_directory)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing subdirectory: Mild Dementia\n",
      "Mild Dementia data saved to Mild Dementia_data.h5\n",
      "Done processing subdirectory: Mild Dementia\n",
      "Processing subdirectory: Very mild Dementia\n",
      "Very mild Dementia data saved to Very mild Dementia_data.h5\n",
      "Done processing subdirectory: Very mild Dementia\n",
      "Processing subdirectory: Moderate Dementia\n",
      "Moderate Dementia data saved to Moderate Dementia_data.h5\n",
      "Done processing subdirectory: Moderate Dementia\n",
      "Processing subdirectory: Non Demented\n",
      "Non Demented data saved to Non Demented_data.h5\n",
      "Done processing subdirectory: Non Demented\n",
      "Class Counts: None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# base_directory = args.img_dir  # Replace with your path\n",
    "# X_dataset, y_dataset, class_counts = load_images_to_tensor(base_directory)\n",
    "\n",
    "# print(f\"Combined Tensor Size: {X_dataset.size()}\")\n",
    "# print(f\"Labels Tensor Size: {y_dataset.size()}\")\n",
    "# print(f\"Class Counts: {class_counts}\")\n",
    "\n",
    "# print(X_dataset.shape)  # This will print (dataset_len, 60, img_height, img_width)\n",
    "# print(y_dataset.shape)  # This will print (dataset_len,)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.11.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.11.4 64-bit ('nlp-m': conda)"
  },
  "interpreter": {
   "hash": "62ef8ab7a50fde946441678ef251eba85852e5ab7813d8beba261a97f4cf7750"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}