{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as sk_OLS\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaller(edu):\n",
    "    x_max = max(edu)\n",
    "    x_min = min(edu)\n",
    "    scaled_xs =[]\n",
    "    for x in edu:\n",
    "        x_scaled = 4*(x-x_min)/(x_max-x_min)+1\n",
    "        scaled_xs.append(x_scaled)\n",
    "    return scaled_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID M/F Hand  Age      Educ  SES  MMSE  CDR  eTIV   nWBV  \\\n",
      "0    OAS1_0001_MR1   F    R   74  2.000000  3.0  29.0  0.0  1344  0.743   \n",
      "1    OAS1_0002_MR1   F    R   55  4.000000  1.0  29.0  0.0  1147  0.810   \n",
      "2    OAS1_0003_MR1   F    R   73  4.000000  3.0  27.0  0.5  1454  0.708   \n",
      "3    OAS1_0004_MR1   M    R   28       NaN  NaN   NaN  NaN  1588  0.803   \n",
      "4    OAS1_0005_MR1   M    R   18       NaN  NaN   NaN  NaN  1737  0.848   \n",
      "..             ...  ..  ...  ...       ...  ...   ...  ...   ...    ...   \n",
      "804            NaN   M    R   82  3.352941  1.0  28.0  0.5  1693  0.694   \n",
      "805            NaN   M    R   86  3.352941  1.0  26.0  0.5  1688  0.675   \n",
      "806            NaN   F    R   61  2.647059  2.0  30.0  0.0  1319  0.801   \n",
      "807            NaN   F    R   63  2.647059  2.0  30.0  0.0  1327  0.796   \n",
      "808            NaN   F    R   65  2.647059  2.0  30.0  0.0  1333  0.801   \n",
      "\n",
      "       ASF  Delay Subject ID         MRI ID        Group  Visit  MR Delay  \\\n",
      "0    1.306    NaN        NaN            NaN          NaN    NaN       NaN   \n",
      "1    1.531    NaN        NaN            NaN          NaN    NaN       NaN   \n",
      "2    1.207    NaN        NaN            NaN          NaN    NaN       NaN   \n",
      "3    1.105    NaN        NaN            NaN          NaN    NaN       NaN   \n",
      "4    1.010    NaN        NaN            NaN          NaN    NaN       NaN   \n",
      "..     ...    ...        ...            ...          ...    ...       ...   \n",
      "804  1.037    NaN  OAS2_0185  OAS2_0185_MR2     Demented    2.0     842.0   \n",
      "805  1.040    NaN  OAS2_0185  OAS2_0185_MR3     Demented    3.0    2297.0   \n",
      "806  1.331    NaN  OAS2_0186  OAS2_0186_MR1  Nondemented    1.0       0.0   \n",
      "807  1.323    NaN  OAS2_0186  OAS2_0186_MR2  Nondemented    2.0     763.0   \n",
      "808  1.317    NaN  OAS2_0186  OAS2_0186_MR3  Nondemented    3.0    1608.0   \n",
      "\n",
      "     EDUC  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "..    ...  \n",
      "804  16.0  \n",
      "805  16.0  \n",
      "806  13.0  \n",
      "807  13.0  \n",
      "808  13.0  \n",
      "\n",
      "[809 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "longitudinal = pd.read_csv(\"datacsv/oasis_longitudinal.csv\")\n",
    "cross_sectional = pd.read_csv(\"datacsv/oasis_cross-sectional.csv\")\n",
    "\n",
    "edu = longitudinal.EDUC\n",
    "scalled_edu = scaller(edu)\n",
    "longitudinal[\"Educ\"] = scalled_edu\n",
    "\n",
    "frames = [cross_sectional, longitudinal]\n",
    "\n",
    "\n",
    "combined = pd.concat(frames)\n",
    "# combined = combined.rename(columns={\"Group\": \"CDR\"})\n",
    "# combined = combined.map(rename)\n",
    "# combined[\"Group\"] = combined[\"Group\"].astype('float')\n",
    "# print(combined)\n",
    "combined.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "print(combined)\n",
    "combined.to_csv(\"combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7515451174289246\n",
      "     Age      Educ  SES  MMSE  CDR  eTIV   nWBV  MR Delay\n",
      "0     74  2.000000  3.0  29.0  0.0  1344  0.743       NaN\n",
      "1     55  4.000000  1.0  29.0  0.0  1147  0.810       NaN\n",
      "2     73  4.000000  3.0  27.0  0.5  1454  0.708       NaN\n",
      "8     74  5.000000  2.0  30.0  0.0  1636  0.689       NaN\n",
      "9     52  3.000000  2.0  30.0  0.0  1321  0.827       NaN\n",
      "..   ...       ...  ...   ...  ...   ...    ...       ...\n",
      "804   82  3.352941  1.0  28.0  0.5  1693  0.694     842.0\n",
      "805   86  3.352941  1.0  26.0  0.5  1688  0.675    2297.0\n",
      "806   61  2.647059  2.0  30.0  0.0  1319  0.801       0.0\n",
      "807   63  2.647059  2.0  30.0  0.0  1327  0.796     763.0\n",
      "808   65  2.647059  2.0  30.0  0.0  1333  0.801    1608.0\n",
      "\n",
      "[608 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cdr_na = combined[\"CDR\"].isna()\n",
    "# print(combined[cdr_na])\n",
    "\n",
    "\n",
    "unlabled = combined[cdr_na]\n",
    "labled = combined[~cdr_na]\n",
    "\n",
    "\n",
    "print(len(labled)/len(combined))\n",
    "\n",
    "y_label = labled.CDR\n",
    "X_label = labled.drop([ \"M/F\", \"Hand\", \"Subject ID\", \"MRI ID\", \"ID\", \"Group\", \"Visit\", \"EDUC\", \"Delay\", \"ASF\"], axis=1)\n",
    "# X_cluster_label = X_label.drop([\"MR Delay\", \"SES\", \"MMSE\"], axis=1)\n",
    "\n",
    "# , \"SES\", \"MMSE\", \"ASF\"\n",
    "x_unlabeled = unlabled.drop([ \"M/F\", \"Hand\", \"Subject ID\", \"MRI ID\", \"ID\", \"Group\", \"Visit\", \"EDUC\", \"Delay\", \"ASF\"], axis=1)\n",
    "print(X_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize values:\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "imp_mean = IterativeImputer(random_state=42)\n",
    "X_label = imp_mean.fit_transform(X_label)\n",
    "X_label = pd.DataFrame(X_label, columns=[\"Age\",\"Educ\",  \"SES\",  \"MMSE\",  \"CDR\",  \"eTIV\",   \"nWBV\",  \"MR Delay\"])\n",
    "X = x_unlabeled\n",
    "x_infered_labels = imp_mean.transform(X)\n",
    "x_infered_labels = pd.DataFrame(x_infered_labels, columns=[\"Age\", \"Educ\", \"SES\", \"MMSE\", \"CDR\", \"eTIV\", \"nWBV\", \"MR Delay\"])\n",
    "frames = [X_label, x_infered_labels]\n",
    "\n",
    "\n",
    "combined = pd.concat(frames)\n",
    "y_label = combined.CDR\n",
    "combined = combined.drop([\"CDR\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=6)\n",
    "x_components = pca.fit_transform(combined)\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606\n",
      "203\n",
      "[[-7.05442724e+01 -1.63423433e+02 -1.02458329e+01 -3.00786002e+00\n",
      "   2.38239280e+00 -4.83707951e-01]\n",
      " [ 5.89419777e+02 -1.81881156e+02 -1.06065910e+01 -1.46452817e+00\n",
      "  -7.26418791e-01  2.40617318e-01]\n",
      " [ 9.83419190e+00  3.90419791e+01  4.08255203e+01 -3.87601453e-02\n",
      "  -2.75005721e-02  6.22068637e-03]\n",
      " ...\n",
      " [-6.13041644e+02 -2.92400061e+02 -8.32304684e+00  2.32812894e+00\n",
      "  -2.17349246e+00 -3.04193077e-01]\n",
      " [ 3.52112198e+01  9.23306928e+01  3.13355066e+01  3.57249318e-01\n",
      "  -1.75820986e-02  6.10786912e-03]\n",
      " [-5.91572272e+02  1.88403438e+01 -1.23241174e+01 -2.11274729e+00\n",
      "   7.03929349e-01 -2.47442924e-01]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_components, y_label)\n",
    "print(len(X_train))\n",
    "# print(y_train)\n",
    "print(len(X_test))\n",
    "print(X_train)\n",
    "# print(X_test)\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9113300492610837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svm = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# y_unlabeled = clf_svm.predict(x_unlabeled)\n",
    "# print(y_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x_un_components = pca.fit_transform(x_infered_labels )\n",
    "\n",
    "y_unlabeled = clf_svm.predict(x_un_components)\n",
    "print(y_unlabeled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
